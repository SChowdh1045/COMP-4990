*************** PLAN ***************
1) ^^^ Fill missing values (only found in categorical features) with mode & NOT DROPPING ANY FEATURES ^^^
2) Fill missing values (only found in categorical features) with mode & DROPPING FEATURES that have low correlation / weak features
3) Delete datapoints (rows) with missing values (only found in categorical features)


4) FEATURE ENGINEERING 1 (from looking at top 10 most correlated features matrix): Create the following feature: Study_Effectiveness = Hours_Studied * Attendance 
and test the performance on the following scenarios:
      1. all_features: Original features + new feature (Study_Effectiveness)
      2. new_feature_only: Original features + new feature WITHOUT Hours_Studied & Attendance
      3. originals_only: Original features only

5) FEATURE ENGINEERING 2: Create the following feature: Study_Life_Balance = Hours_Studied / (Sleep_Hours + Physical_Activity)
and test the performance on the same previous scenarios.

6) FEATURE ENGINEERING 3 (Same name as case FE-1 but different implementation): Create the following feature: Study_Effectiveness = Previous_Scores / (Hours_Studied + 1)  # +1 to avoid division by zero
and test the performance on the same previous scenarios.


7) ^^^ Remove rows with exam score greater than 100 (Outlier) ^^^


8) Try Polynomial Regression with degrees 1-3


9) Try the following models: Linear Regression, Decision Tree, Random Forest, Support Vector Regression, Gradient Boosting, XGBoost, Ridge, Lasso


10) ^^^ Case 7 + Case 2 (i.e. removing outlier then dropping weak features) ^^^


11) Case 10 + Case 8 (Polynomial Regression with degrees 1-3)


12) Case 10 + Case 9 (Trying out different models)


13) SYNTHETIC DATASET + CASE 10




*************** PLANNED OBSERVATIONS (on Testing ONLY)  ***************

*** CASE 1 ***
R² Score: 0.7696 %
RMSE: 1.8044



*** CASE 2: ***
Results get increasingly worse for every additional weak feature dropped. Worst result was when all weak features were dropped:
R² Score: 0.7572 %
RMSE: 1.8524



*** CASE 3 ***
R² Score: 0.7314 %
RMSE: 2.0429



*** CASE 4 ***
Results for all_features (MARGINALLY BEST):
R² Score: 0.7699 %
RMSE: 1.8033


Results for new_feature_only (WORST):
R² Score: 0.6422 %
RMSE: 2.2489


Results for originals_only (same as Case 1):
R² Score: 0.7696 %
RMSE: 1.8044



*** CASE 5 ***
Results for all_features:
R² Score: 0.7698 %
RMSE: 1.8040

Results for new_feature_only:
R² Score: 0.6794 %
RMSE: 2.1289

Results for original_only (same as Case 1):
R² Score: 0.7696 %
RMSE: 1.8044



*** CASE 6 ***
Results for all_features:
R² Score: 0.7685 %
RMSE: 1.8088

Results for new_feature_only:
R² Score: 0.5688 %
RMSE: 2.4688

Results for original_only (same as Case 1):
R² Score: 0.7696 %
RMSE: 1.8044



*** CASE 7 ***
R² Score: 0.8250 %
RMSE: 1.5213



*** CASE 8 ***
Degree 1 Results (just Linear Regression):
R² Score: 0.8250 %
RMSE: 1.5213

Degree 2 Results:
R² Score: 0.7996 %
RMSE: 1.6279

Degree 3 Results (Shows clear overfitting - training results were very good but testing is very bad):
R² Score: -0.3387 %
RMSE: 4.2075



*** CASE 9 ***
Linear Regression Results:
R² Score: 0.8250 %
RMSE: 1.5213

SVR Results:
R² Score: 0.8184 %
RMSE: 1.5498

Decision Tree Results:
R² Score: 0.0367 %
RMSE: 3.5691

Random Forest Results:
R² Score: 0.6928 %
RMSE: 2.0157

Gradient Boosting Results:
R² Score: 0.7797 %
RMSE: 1.7069

XGBoost Results:
R² Score: 0.7116 %
RMSE: 1.9530

Ridge Results:
R² Score: 0.8248 %
RMSE: 1.5222

Lasso Results:
R² Score: -0.0020 %
RMSE: 3.6401



*** CASE 10 ***
all removed:
R² Score: 0.8052
RMSE: 1.6049

weakest numericals - health removed ('Sleep_Hours', 'Physical_Activity'):
R² Score: 0.8206
RMSE: 1.5405

weakest categoricals removed ('School_Type', 'Gender', 'Peer_Influence'):
R² Score: 0.8121
RMSE: 1.5764

weakest numericals + weakest categoricals removed:
R² Score: 0.8076
RMSE: 1.5950

weakest numerical removed ('Sleep_Hours'):
R² Score: 0.8251
RMSE: 1.5209

Sleep_Hours + School_Type removed     *** (BEST) ***:
R² Score: 0.8251
RMSE: 1.5210

school-related removed ('School_Type', 'Distance_from_Home'):
R² Score: 0.8162
RMSE: 1.5592

demographics removed ('Gender', 'Internet_Access'):
R² Score: 0.8185
RMSE: 1.5494

** Since Sleep_Hours + School_Type removed was best, I tried with all other features as a third feature to be removed, but R² Score was always < 0.82 **



*** CASE 11 ***
Degree 1 Results (just Linear Regression):
R² Score: 0.8251 %
RMSE: 1.5210

Degree 2 Results:
R² Score: 0.8069 %
RMSE: 1.5979

Degree 3 Results (Shows clear overfitting - training results were very good but testing is very bad):
R² Score: 0.2506 %
RMSE: 3.1481



*** CASE 12 ***
Linear Regression Results:
R² Score: 0.8251 %
RMSE: 1.5210

SVR Results:
R² Score: 0.8204 %
RMSE: 1.5410

Decision Tree Results:
R² Score: 0.1090 %
RMSE: 3.4325

Random Forest Results:
R² Score: 0.7018 %
RMSE: 1.9858

Gradient Boosting Results:
R² Score: 0.7729 %
RMSE: 1.7330

XGBoost Results:
R² Score: 0.7139 %
RMSE: 1.9452

Ridge Results:
R² Score: 0.8249 %
RMSE: 1.5219

Lasso Results:
R² Score: -0.0020 %
RMSE: 3.6401



*** CASE 13 ***   (BEST)
R² Score: 0.8431 %
RMSE: 5.7591